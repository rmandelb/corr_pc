{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "criminal-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_keys=['rp','r','jk','cov','corr','jk_err','jkerr','data','data0']\n",
    "class cov_corr():\n",
    "    def mean_calc(self,data=[],axis=1):\n",
    "        return np.mean(data,axis)\n",
    "\n",
    "    def var_calc(self,data=[],axis=1):\n",
    "        return np.var(data,axis)\n",
    "\n",
    "    def residual_calc(self,data=[],axis=1): #calculate residual that go into cov calculation, y-E(y)\n",
    "        mean=self.mean_calc(data,axis)\n",
    "        dim0=len(mean)\n",
    "        dim1=np.shape(data)[axis]\n",
    "        #print dim0,dim1,axis\n",
    "# since mean is always 1-d array, [mean]*dim1 always give matrix [dim0 X dim1]...\n",
    "#hence depending on dimension of data may need to transpose to get correct residuals\n",
    "        try:\n",
    "            res=data-np.transpose([mean]*dim1)\n",
    "            print (\"transpose\")\n",
    "        except:\n",
    "            res=data-[mean]*dim1\n",
    "        return res\n",
    "\n",
    "    def cov_matrix2(self,data=[],axis=1,ddof=0):\n",
    "        return np.cov(data,rowvar=axis)\n",
    "\n",
    "    def cov_matrix(self,data=[],axis=1,ddof=0):\n",
    "        #return np.cov(data,rowvar=axis,ddof=1) #ddof=0 for correct variance\n",
    "        mean=self.mean_calc(data,axis)\n",
    "        dim0=len(mean)\n",
    "        dim1=np.shape(data)[axis]\n",
    "        res=self.residual_calc(data=data,axis=axis)\n",
    "        cov=np.zeros((dim0,dim0))\n",
    "        if len(res[0])!=dim1:\n",
    "            res=np.transpose(res)#residual has dimension of data..\n",
    "                                #depending on axis value, may need to transpose for correct covariance\n",
    "        for i in np.arange(dim0):\n",
    "            for j in np.arange(dim0):\n",
    "                cov[i][j]+=np.sum(res[i]*res[j])\n",
    "        cov/=np.float64(dim1-ddof)\n",
    "        return cov\n",
    "\n",
    "    def cross_cov_matrix2(self,data1=[],data2=[],axis=1,ddof=0):\n",
    "        cross_cov=np.cov(data1,data2,rowvar=axis)\n",
    "        N1=len(data1[0])\n",
    "        N2=len(data2[0])\n",
    "        cov2=np.zeros((N1,N2))\n",
    "        for i in np.arange(N1):\n",
    "            for j in np.arange(N2):\n",
    "                cov2[i][j]=cross_cov[i+N1][j]\n",
    "        return cov2\n",
    "\n",
    "    def cross_cov_matrix(self,data1=[],data2=[],axis=1,ddof=0):\n",
    "    #return np.cov(data,rowvar=axis,ddof=1) #ddof=0 for correct variance\n",
    "        mean1=self.mean_calc(data1,axis)\n",
    "        mean2=self.mean_calc(data2,axis)\n",
    "        dim0=len(mean1)\n",
    "        dim2=len(mean2)\n",
    "        dim1=np.shape(data1)[axis]\n",
    "        res1=self.residual_calc(data=data1,axis=axis)\n",
    "        res2=self.residual_calc(data=data2,axis=axis)\n",
    "        cov=np.zeros((dim0,dim2))\n",
    "        if dim0!=dim2:\n",
    "            print ('cross cov: dimensions of data 1 and data2 not equal')\n",
    "        if len(res1[0])!=dim1:\n",
    "            res2=np.transpose(res2)\n",
    "            res1=np.transpose(res1)#residual has dimension of data..\n",
    "                            #depending on axis value, may need to transpose for correct covariance\n",
    "        for i in np.arange(dim0):\n",
    "            for j in np.arange(dim2):\n",
    "                cov[i][j]+=np.sum(res1[i]*res2[j])\n",
    "        cov/=np.float64(dim1-ddof)\n",
    "        return cov\n",
    "\n",
    "    #for some reason numpy covariance matrix has some constant multiplied to it..\n",
    "    #seems to be some func of N but can't figure it out.\n",
    "    #this func returns that constants value by comparing it with variance\n",
    "    def var_cov_comparison(self,var=[],cov=[]):\n",
    "        l=len(cov[0])\n",
    "        v2=np.zeros_like(var)\n",
    "        for i in np.arange(l):\n",
    "            v2[i]=cov[i][i]\n",
    "        r=var/v2\n",
    "        x=r==r[0]\n",
    "        if sum(x)<l:\n",
    "            print (\"variance-covariance miss match\") #return full ratio array in case r is not constant\n",
    "            return r  #note comparison can be easily fooled due to floating point error\n",
    "        return [r[0]]\n",
    "\n",
    "    def corr_matrix(self,cov_mat=[]): #correlation matrix\n",
    "        diag=np.diag(cov_mat)\n",
    "        return cov_mat/np.sqrt(np.outer(diag,diag))\n",
    "        # dim=len(cov_mat[0])\n",
    "        # var=np.zeros(dim)\n",
    "        # corr=np.zeros((dim,dim))\n",
    "        # for i in np.arange(dim):\n",
    "        #     var[i]=cov_mat[i][i]\n",
    "        # for i in np.arange(dim):\n",
    "        #     for j in np.arange(dim):\n",
    "        #         corr[i][j]=cov_mat[i][j]/np.sqrt(var[i]*var[j])\n",
    "        # return corr\n",
    "\n",
    "    def cross_corr_matrix(self,cov_mat=[],data1=[],data2=[],axis=1): #correlation matrix\n",
    "        dim=len(cov_mat[0])\n",
    "        var1=self.var_calc(data1,axis)\n",
    "        var2=self.var_calc(data2,axis)\n",
    "        corr=np.zeros((dim,dim))\n",
    "#        for i in np.arange(dim):\n",
    " #           var[i]=cov_mat[i][i]\n",
    "        for i in np.arange(dim):\n",
    "            for j in np.arange(dim):\n",
    "                corr[i][j]=cov_mat[i][j]/np.sqrt(var1[i]*var2[j])\n",
    "        return corr\n",
    "\n",
    "    #stack column from various dictionary elements to get a data matrix which goes into covariance calculations\n",
    "    #incase dict elements have several columns, var defines the column to be used. better to have named columns\n",
    "    def dict_stack(self,dic={},var='',ignore_keys=ignore_keys):\n",
    "        keys=dic.keys()\n",
    "        j=0\n",
    "        mat=[]\n",
    "        axis=0\n",
    "        for i in keys:\n",
    "            if i in ignore_keys:\n",
    "                #print 'cov_corr.dict_stack::',i,'ignored in stacking'\n",
    "                continue\n",
    "            if j==0:\n",
    "                if not check_empty(var):\n",
    "                    mat=dic[i][var]\n",
    "                else:\n",
    "                    mat=dic[i]#[:]\n",
    "                j=j+1\n",
    "                continue\n",
    "            if not check_empty(var):\n",
    "                mat=np.vstack((mat,dic[i][var]))\n",
    "            else:\n",
    "                mat=np.vstack((mat,dic[i]))#dic[i][:]\n",
    "        return mat,axis\n",
    "\n",
    "\n",
    "    def dict_cov(self,dic={},var='',stack=0,axis=0,ddof=0,ignore_keys=ignore_keys):\n",
    "        if stack!=0:\n",
    "            #print \"cov_corr: Stacking dictionary\"\n",
    "            mat,axis=self.dict_stack(dic=dic,var=var,ignore_keys=ignore_keys)\n",
    "            #print \"cov_corr: dictionary stacked\"\n",
    "        if stack==0:\n",
    "            #print \"no stacking:\",var,axis\n",
    "            mat=dic[var]\n",
    "            axis=axis\n",
    "        cov=self.cov_matrix2(data=mat,axis=axis,ddof=ddof)\n",
    "        #print cov.shape\n",
    "        corr=self.corr_matrix(cov)\n",
    "        return cov,corr\n",
    "\n",
    "\n",
    "    def dict_cross_cov(self,dic={},dic2={},var1='',var2='',stack=0,axis=0,ddof=0):\n",
    "        if stack!=0:\n",
    "            #print \"cov_corr: Stacking dictionary\"\n",
    "            mat1,axis=self.dict_stack(dic=dic,var=var1)\n",
    "            if dic2:\n",
    "                mat2,axis=self.dict_stack(dic=dic2,var=var2)\n",
    "            else:\n",
    "                mat2,axis=self.dict_stack(dic=dic,var=var2)\n",
    "        if stack==0:\n",
    "            #print \"no stacking:\",var,axis\n",
    "            mat1=dic[var1]\n",
    "            if dic2:\n",
    "                mat2=dic2[var2]\n",
    "            else:\n",
    "                mat2=dic[var2]\n",
    "            axis=axis\n",
    "        cov=self.cross_cov_matrix2(data1=mat1,data2=mat2,axis=axis,ddof=ddof)\n",
    "        corr=self.cross_corr_matrix(cov_mat=cov,data1=mat1,data2=mat2,axis=axis)\n",
    "        return cov,corr\n",
    "\n",
    "    def matrix_diagonalize(self,m=[]):\n",
    "        N1=len(m)\n",
    "        N2=len(m[0])\n",
    "        for i in np.arange(N1):\n",
    "            for j in np.arange(N2):\n",
    "                if i==j:\n",
    "                    continue\n",
    "                m[i][j]=0\n",
    "        return m\n",
    "\n",
    "    def mat_inv(self,m=[]):\n",
    "        return np.linalg.inv(m)\n",
    "\n",
    "    def matrix_cut(self,mat=[],x=[]):\n",
    "        m=mat[x]\n",
    "        N=sum(x)\n",
    "        m2=np.zeros((N,N))\n",
    "        j=0\n",
    "        for i in m:\n",
    "            m2[j]=i[x]\n",
    "            j=j+1\n",
    "        return m2\n",
    "\n",
    "    def chi_sq(self,theory=[],data=[],x=[],cov=[]):\n",
    "        if len(x):\n",
    "            data=data[x]\n",
    "            theory=theory[x]\n",
    "            cov=self.matrix_cut(mat=cov,x=x)\n",
    "        cov_inv=self.mat_inv(m=cov)\n",
    "        #print data.shape,theory.shape,cov.shape,cov_inv.shape\n",
    "        N=len(data)\n",
    "        chi_sq=0\n",
    "        for i in np.arange(N):\n",
    "            for j in np.arange(N):\n",
    "                chi_sq+=((data[i]-theory[i])*(data[j]-theory[j])*(cov_inv[i][j]))\n",
    "        #chi_sq/=2.\n",
    "        return chi_sq,N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "structured-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jk_read(dataset='',var=None,njk=100,auto_cross='_cross',bins='_bins',\n",
    "            home='',corr='_final',skiprows=0,**kwargs):\n",
    "    data_jk={}\n",
    "    filename=dataset\n",
    "    try:\n",
    "        data_jk['data']=np.genfromtxt(home+filename+bins+auto_cross+'_jk_final.dat',\n",
    "                                      names=True,skip_header=skiprows)\n",
    "    except:\n",
    "        print ('file not found',home+filename+bins+auto_cross+'_jk_final.dat')\n",
    "    try:\n",
    "        data_jk['data0']=np.genfromtxt(home+filename+bins+auto_cross+corr+'.dat',\n",
    "                                       names=True,skip_header=skiprows)\n",
    "    except:\n",
    "        print ('file not found',home+filename+bins+auto_cross+corr+'.dat')\n",
    "    for i in np.arange(njk):\n",
    "        data_jk[i]=np.genfromtxt(home+filename+bins+auto_cross+'_jk'+str(i)+corr+'.dat',names=True,\n",
    "                                 skip_header=skiprows)\n",
    "    cc=cov_corr()\n",
    "    if var and njk>0:\n",
    "        data_jk['cov']={}\n",
    "        data_jk['corr']={}\n",
    "        for v in var:\n",
    "            cov,corr=cc.dict_cov(dic=data_jk,var=v,stack=1,ignore_keys=['data','data0','cov','corr'])\n",
    "            cov*=njk-1.\n",
    "            data_jk['cov'][v]=cov\n",
    "            data_jk['corr'][v]=corr\n",
    "    return data_jk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extended-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_home='./temp/hsc_test/corr_data_out/'\n",
    "file_name='hsc_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dirty-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "njk=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "impressed-dining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file not found ./temp/hsc_test/corr_data_out/hsc_test_bins_cross_jk_final.dat\n"
     ]
    }
   ],
   "source": [
    "w_jk=jk_read(dataset=file_name,var=['wgg','wgp'],njk=njk,auto_cross='_cross',bins='_bins',\n",
    "            home=file_home,corr='_final',skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "spread-singing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data0'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_jk.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f19894a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0.129245,    3328., 0., 0.,  0.00934529,  0., -0.00680549, -0., 0., 0., 0., 0., 0., 0., -6.88021, -0., 0.,    3328., 0.1     ,  0.158489, 0.),\n",
       "       (0.204839,    7185., 0., 0., -0.00258386, -0.,  0.00872609,  0., 0., 0., 0., 0., 0., 0., -6.86842, -0., 0.,    7185., 0.158489,  0.251189, 0.),\n",
       "       (0.324648,   15355., 0., 0., -0.00316065, -0., -0.00174473, -0., 0., 0., 0., 0., 0., 0., -6.90942, -0., 0.,   15355., 0.251189,  0.398107, 0.),\n",
       "       (0.514532,   31891., 0., 0., -0.00308426, -0.,  0.00314672,  0., 0., 0., 0., 0., 0., 0., -6.9076 , -0., 0.,   31891., 0.398107,  0.630957, 0.),\n",
       "       (0.815479,   67748., 0., 0., -0.00120796, -0., -0.00215722, -0., 0., 0., 0., 0., 0., 0., -6.9079 , -0., 0.,   67748., 0.630957,  1.      , 0.),\n",
       "       (1.29245 ,  132112., 0., 0.,  0.00112028,  0.,  0.00357882,  0., 0., 0., 0., 0., 0., 0., -6.90481, -0., 0.,  132112., 1.      ,  1.58489 , 0.),\n",
       "       (2.04839 ,  255198., 0., 0.,  0.0012611 ,  0., -0.0005873 , -0., 0., 0., 0., 0., 0., 0., -6.88166, -0., 0.,  255198., 1.58489 ,  2.51189 , 0.),\n",
       "       (3.24648 ,  513393., 0., 0.,  0.00048746,  0.,  0.00085679,  0., 0., 0., 0., 0., 0., 0., -6.87106, -0., 0.,  513393., 2.51189 ,  3.98107 , 0.),\n",
       "       (5.14532 , 1002919., 0., 0., -0.000622  , -0., -0.00039801, -0., 0., 0., 0., 0., 0., 0., -6.86383, -0., 0., 1002920., 3.98107 ,  6.30957 , 0.),\n",
       "       (8.15479 , 1746213., 0., 0., -0.00086452, -0., -0.00016821, -0., 0., 0., 0., 0., 0., 0., -6.86343, -0., 0., 1746210., 6.30957 , 10.      , 0.)],\n",
       "      dtype=[('rp', '<f8'), ('npairs', '<f8'), ('wgg', '<f8'), ('wgg_err', '<f8'), ('wgp', '<f8'), ('wgp_err', '<f8'), ('wgx', '<f8'), ('wgx_err', '<f8'), ('wpp', '<f8'), ('wpp_err', '<f8'), ('wxx', '<f8'), ('wxx_err', '<f8'), ('wpx', '<f8'), ('wpx_err', '<f8'), ('theta', '<f8'), ('theta_err', '<f8'), ('LS_err', '<f8'), ('wt_npair', '<f8'), ('rp_low', '<f8'), ('rp_high', '<f8'), ('sig_crit', '<f8')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_jk['data0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5204f4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3328.,    7185.,   15355.,   31891.,   67748.,  132112.,\n",
       "        255198.,  513393., 1002919., 1746213.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_jk['data0']['npairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b09db52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00934529, -0.00258386, -0.00316065, -0.00308426, -0.00120796,\n",
       "        0.00112028,  0.0012611 ,  0.00048746, -0.000622  , -0.00086452])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_jk['data0']['wgp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-underwear",
   "metadata": {},
   "source": [
    "'data': contains the jackknife mean and the jackknife errorbars\n",
    "\n",
    "'data0': Contains the full sample measurements. Do not use the errorbars from this set.\n",
    "\n",
    "0....njk-1: Contains measurements from the respective jackknife regions.\n",
    "\n",
    "cov, corr: Covariance and correlation matrices for the variables passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e26aaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file not found ./temp/hsc_test/corr_data_out/hsc_test_bins_cross_jk_final.dat\n",
      "file not found ./temp/hsc_test/corr_data_out/hsc_test_bins2D_cross_jk_final.dat\n",
      "file not found ./temp/hsc_test/corr_data_out/hsc_test_bins_cross_jk_final.dat\n",
      "file not found ./temp/hsc_test/corr_data_out/hsc_test_bins2D_cross_jk_final.dat\n",
      "file not found ./temp/hsc_test/corr_data_out/hsc_test_bins_cross_jk_final.dat\n"
     ]
    }
   ],
   "source": [
    "#following are for debugging if needed\n",
    "RRjk=jk_read(dataset=file_name,var=['wgg'],njk=njk,auto_cross='_cross',bins='_bins',\n",
    "            home=file_home,corr='_RR',skiprows=0)\n",
    "RR2jk=jk_read(dataset=file_name,var=['wgg'],njk=njk,auto_cross='_cross',bins='_bins2D',\n",
    "            home=file_home,corr='_RR',skiprows=0)\n",
    "SDjk=jk_read(dataset=file_name,var=['wgg'],njk=njk,auto_cross='_cross',bins='_bins',\n",
    "            home=file_home,corr='_SD',skiprows=0)\n",
    "SD2jk=jk_read(dataset=file_name,var=['wgg'],njk=njk,auto_cross='_cross',bins='_bins2D',\n",
    "            home=file_home,corr='_SD',skiprows=0)\n",
    "\n",
    "SRjk=jk_read(dataset=file_name,var=['wgg'],njk=njk,auto_cross='_cross',bins='_bins',\n",
    "            home=file_home,corr='_SR',skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a173a05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "scenic-vertex",
   "metadata": {},
   "source": [
    "# For derived quantities such as bias, compute jk errors as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collect-transsexual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file not found ./temp/hsc_test/corr_data_out/hsc_test_bins_cross_jk_final.dat\n",
      "file not found ./temp/hsc_test/corr_data_out/hsc_test_bins_cross_jk_final.dat\n"
     ]
    }
   ],
   "source": [
    "# say we want to compute bias using wgg/wmm ratio\n",
    "wgg=jk_read(dataset=file_name,var=['wgg','wgp'],njk=njk,auto_cross='_cross',bins='_bins',\n",
    "            home=file_home,corr='_final',skiprows=0) \n",
    "\n",
    "wmm=jk_read(dataset=file_name,var=['wgg','wgp'],njk=njk,auto_cross='_cross',bins='_bins',\n",
    "            home=file_home,corr='_final',skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broad-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/verafs/scratch/phy200040p/sukhdeep/miniconda3/envs/intel/lib/python3.7/site-packages/ipykernel_launcher.py:91: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "bias={}\n",
    "njk=njk\n",
    "for i in np.arange(njk):\n",
    "    bias[i]=np.sqrt(wgg[i]['wgg']/wmm[i]['wgg'])\n",
    "cc=cov_corr()\n",
    "bias['cov'],bias['corr']=cc.dict_cov(dic=bias,stack=1) #in this example values are non-sensicle because we used the same calculations for wgg and wmm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-briefing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel",
   "language": "python",
   "name": "intel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
